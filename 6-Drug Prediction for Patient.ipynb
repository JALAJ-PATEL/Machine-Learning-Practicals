{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fdffe34-b7f5-42cf-923f-3532e87b8f2e",
   "metadata": {},
   "source": [
    "# Drug Prediction for Patient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c064c06-f7b2-4b43-97a7-4c4841c51adc",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "The dataset contains information about drug classification based on the general information and diagnosis of patients. \n",
    "\n",
    "## Objective:\n",
    "The task is to develop a machine learning model that can predict the appropriate type of drug suitable for a patient based on their provided data. This model will aid in personalized drug prescription, ensuring better patient care and treatment outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3904f-915d-4dc8-be5e-e0655abc2d42",
   "metadata": {},
   "source": [
    "### Loading Dataset and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac421d31-9faa-47c9-aa60-2b419dbf723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
      "0   23   F    HIGH        HIGH   25.355  drugY\n",
      "1   47   M     LOW        HIGH   13.093  drugC\n",
      "2   47   M     LOW        HIGH   10.114  drugC\n",
      "3   28   F  NORMAL        HIGH    7.798  drugX\n",
      "4   61   F     LOW        HIGH   18.043  drugY\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Age          200 non-null    int64  \n",
      " 1   Sex          200 non-null    object \n",
      " 2   BP           200 non-null    object \n",
      " 3   Cholesterol  200 non-null    object \n",
      " 4   Na_to_K      200 non-null    float64\n",
      " 5   Drug         200 non-null    object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "              Age     Na_to_K\n",
      "count  200.000000  200.000000\n",
      "mean    44.315000   16.084485\n",
      "std     16.544315    7.223956\n",
      "min     15.000000    6.269000\n",
      "25%     31.000000   10.445500\n",
      "50%     45.000000   13.936500\n",
      "75%     58.000000   19.380000\n",
      "max     74.000000   38.247000\n",
      "\n",
      "Missing Values:\n",
      "Age            0\n",
      "Sex            0\n",
      "BP             0\n",
      "Cholesterol    0\n",
      "Na_to_K        0\n",
      "Drug           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('drug200.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to get an overview\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the information of the dataset (data types, non-null counts)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Get the statistical summary of the dataset for numerical columns\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd29c6-f6ee-4b00-b06f-0653297af962",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5e956f-76c5-4804-bc44-de3f67f81f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encoding the 'Sex' column\n",
    "df['Sex'] = label_encoder.fit_transform(df['Sex'])\n",
    "\n",
    "# Encoding the 'BP' and 'Cholesterol' columns\n",
    "bp_mapping = {'LOW': 0, 'NORMAL': 1, 'HIGH': 2}\n",
    "cholesterol_mapping = {'NORMAL': 0, 'HIGH': 1}\n",
    "df['BP'] = df['BP'].map(bp_mapping)\n",
    "df['Cholesterol'] = df['Cholesterol'].map(cholesterol_mapping)\n",
    "\n",
    "# Encoding the target variable 'Drug'\n",
    "df['Drug'] = label_encoder.fit_transform(df['Drug'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7d0eb-c6f9-4936-bc7e-2bd04b5cedd6",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca4e9158-0634-4ee5-8252-33bda9cf2266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpate\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 1.0\n",
      "k-NN Accuracy: 0.8833333333333333\n",
      "Logistic Regression Accuracy: 0.8666666666666667\n",
      "SVM Accuracy: 0.95\n",
      "\n",
      "Decision Tree Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "\n",
      "k-NN Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.50      1.00      0.67         3\n",
      "           2       1.00      0.33      0.50         6\n",
      "           3       0.82      1.00      0.90        18\n",
      "           4       1.00      0.88      0.94        26\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.86      0.84      0.80        60\n",
      "weighted avg       0.92      0.88      0.88        60\n",
      "\n",
      "\n",
      "Logistic Regression Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.75      1.00      0.86         3\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.74      0.94      0.83        18\n",
      "           4       0.96      0.96      0.96        26\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.69      0.78      0.73        60\n",
      "weighted avg       0.79      0.87      0.82        60\n",
      "\n",
      "\n",
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83         7\n",
      "           1       0.50      1.00      0.67         3\n",
      "           2       1.00      1.00      1.00         6\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      0.96      0.98        26\n",
      "\n",
      "    accuracy                           0.95        60\n",
      "   macro avg       0.90      0.94      0.90        60\n",
      "weighted avg       0.97      0.95      0.96        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpate\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jpate\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jpate\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X = df.drop(columns=['Drug'])\n",
    "y = df['Drug']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[['Age', 'Na_to_K']] = scaler.fit_transform(X_train[['Age', 'Na_to_K']])\n",
    "X_test_scaled[['Age', 'Na_to_K']] = scaler.transform(X_test[['Age', 'Na_to_K']])\n",
    "\n",
    "# Initialize models\n",
    "dt_model = DecisionTreeClassifier()  # No scaling needed for Decision Tree\n",
    "knn_model = KNeighborsClassifier()   # Needs scaling\n",
    "lr_model = LogisticRegression(multi_class='ovr')  # Needs scaling, OvR for multiclass\n",
    "svm_model = SVC()  # Needs scaling\n",
    "\n",
    "# Train models\n",
    "dt_model.fit(X_train, y_train)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"k-NN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nDecision Tree Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nk-NN Report:\\n\", classification_report(y_test, y_pred_knn))\n",
    "print(\"\\nLogistic Regression Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"\\nSVM Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128fc58-f77f-445e-a613-61ec96661c9b",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c201ae1-dbd6-47c6-b110-41061e12a4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Decision Tree:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "==============================\n",
      "Performance of k-NN:\n",
      "Accuracy: 0.8833\n",
      "Precision: 0.9205\n",
      "Recall: 0.8833\n",
      "==============================\n",
      "Performance of Logistic Regression:\n",
      "Accuracy: 0.8667\n",
      "Precision: 0.7926\n",
      "Recall: 0.8667\n",
      "==============================\n",
      "Performance of SVM:\n",
      "Accuracy: 0.9500\n",
      "Precision: 0.9750\n",
      "Recall: 0.9500\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpate\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_model_performance(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Performance of {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "# Evaluate models' performance\n",
    "evaluate_model_performance(y_test, y_pred_dt, \"Decision Tree\")\n",
    "evaluate_model_performance(y_test, y_pred_knn, \"k-NN\")\n",
    "evaluate_model_performance(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "evaluate_model_performance(y_test, y_pred_svm, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715752a3-417c-4031-88d7-6c83fa51a73b",
   "metadata": {},
   "source": [
    "### Conclusion of the Drug Prediction Model\n",
    "\n",
    "The goal of this project was to predict the type of drug that a patient should be prescribed based on several features using various classification models. Below is a summary of the performance of each model:\n",
    "\n",
    "1. **Decision Tree**:\n",
    "   - Achieved a perfect score in all metrics: Accuracy, Precision, and Recall were all **1.0000**.\n",
    "   - The Decision Tree model correctly classified every instance in the test set.\n",
    "   - It demonstrates that Decision Tree may have a tendency to **overfit** to the training data, especially if the dataset is small.\n",
    "\n",
    "2. **k-Nearest Neighbors (k-NN)**:\n",
    "   - Accuracy: **0.8833**\n",
    "   - Precision: **0.9205**\n",
    "   - Recall: **0.8833**\n",
    "   - The k-NN model performed well with high precision, indicating it was accurate in predicting the correct drug class.\n",
    "   - This model may have some issues with misclassifications, but still provides a good balance between sensitivity (Recall) and specificity.\n",
    "\n",
    "3. **Logistic Regression**:\n",
    "   - Accuracy: **0.8667**\n",
    "   - Precision: **0.7926**\n",
    "   - Recall: **0.8667**\n",
    "   - The Logistic Regression model performed decently, indicating that the relationship between features and the target variable might not be strictly linear.\n",
    "   - Precision was lower compared to other models, suggesting that it might not perform as well in minimizing false positives.\n",
    "\n",
    "4. **Support Vector Machine (SVM)**:\n",
    "   - Accuracy: **0.9500**\n",
    "   - Precision: **0.9750**\n",
    "   - Recall: **0.9500**\n",
    "   - The SVM model was one of the best-performing models after the Decision Tree, with a high level of accuracy and precision.\n",
    "   - SVM shows robustness in handling complex relationships between features and provides a good generalization capability.\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Decision Tree** provides excellent accuracy, but may suffer from overfitting on smaller datasets. It’s important to validate with larger or more varied data.\n",
    "- **k-NN** shows a strong performance, although it can be sensitive to the choice of `k` and data scaling. It requires scaling to handle numerical differences among features.\n",
    "- **Logistic Regression** might not be the best choice for this problem due to its lower precision, but it offers interpretability and simplicity.\n",
    "- **SVM** performed well, handling complexity with high precision and accuracy, making it a strong candidate when dealing with non-linear data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
